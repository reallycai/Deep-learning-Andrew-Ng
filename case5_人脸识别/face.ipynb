{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "needed-softball",
   "metadata": {},
   "source": [
    "# 人脸识别\n",
    "### 用Inception网络搭建的人脸识别框架，由于图片通道放在了第一维度，需要用tensorflow-gpu跑哦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"2\"\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import fr_utils as u\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "#K.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_encoding(image_path, model):\n",
    "    img1 = cv2.imread(image_path, 1)\n",
    "    img = img1[...,::-1]\n",
    "    img = tf.transpose(img, (2,0,1))/255    # 此处img类型为tf.int8，如果除255.0会因为类型不同报错\n",
    "    x_train = tf.convert_to_tensor(img)[tf.newaxis,...]     # 使用tf.newaxis为数组增加一个维度\n",
    "    print(x_train.shape)\n",
    "    #re_train=tf.transpose(x_train,perm=[0,2,3,1])\n",
    "    #print(re_train.shape)\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_database(FRmodel):\n",
    "    \"\"\"\n",
    "    创建面部识别的数据库\n",
    "    Returns:\n",
    "        database: 包含姓名和对应面部编码的字典\n",
    "    \"\"\"\n",
    "    database = {}\n",
    "    database[\"danielle\"] = img_to_encoding(\"./images/danielle.png\", FRmodel)\n",
    "    database[\"younes\"] = img_to_encoding(\"./images/younes.jpg\", FRmodel)\n",
    "    database[\"tian\"] = img_to_encoding(\"./images/tian.jpg\", FRmodel)\n",
    "    database[\"andrew\"] = img_to_encoding(\"./images/andrew.jpg\", FRmodel)\n",
    "    database[\"kian\"] = img_to_encoding(\"./images/kian.jpg\", FRmodel)\n",
    "    database[\"dan\"] = img_to_encoding(\"./images/dan.jpg\", FRmodel)\n",
    "    database[\"sebastiano\"] = img_to_encoding(\"./images/sebastiano.jpg\", FRmodel)\n",
    "    database[\"bertrand\"] = img_to_encoding(\"./images/bertrand.jpg\", FRmodel)\n",
    "    database[\"kevin\"] = img_to_encoding(\"./images/kevin.jpg\", FRmodel)\n",
    "    database[\"felix\"] = img_to_encoding(\"./images/felix.jpg\", FRmodel)\n",
    "    database[\"benoit\"] = img_to_encoding(\"./images/benoit.jpg\", FRmodel)\n",
    "    database[\"arnaud\"] = img_to_encoding(\"./images/arnaud.jpg\", FRmodel)\n",
    "\n",
    "    return database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    \"\"\"\n",
    "    根据公式（4）实现三元组损失函数\n",
    "    \n",
    "    参数：\n",
    "        y_true -- true标签，当你在Keras里定义了一个损失函数的时候需要它，但是这里不需要。\n",
    "        y_pred -- 列表类型，包含了如下参数：\n",
    "            anchor -- 给定的“anchor”图像的编码，维度为(None,128)\n",
    "            positive -- “positive”图像的编码，维度为(None,128)\n",
    "            negative -- “negative”图像的编码，维度为(None,128)\n",
    "        alpha -- 超参数，阈值\n",
    "    \n",
    "    返回：\n",
    "        loss -- 实数，损失的值\n",
    "    \"\"\"\n",
    "    #获取anchor, positive, negative的图像编码\n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    #第一步：计算\"anchor\" 与 \"positive\"之间编码的距离，这里需要使用axis=-1\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)),axis=-1)\n",
    "    \n",
    "    #第二步：计算\"anchor\" 与 \"negative\"之间编码的距离，这里需要使用axis=-1\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)),axis=-1)\n",
    "    \n",
    "    #第三步：减去之前的两个距离，然后加上alpha\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist,neg_dist),alpha)\n",
    "    \n",
    "    #通过取带零的最大值和对训练样本的求和来计算整个公式\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss,0))\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(image_path, identity, database, model):\n",
    "    \"\"\"\n",
    "    人脸认证，比较摄像头图像与id信息是否符合，即比较库中identity的编码和image_path的编码（即全连接层的输出）\n",
    "    Args:\n",
    "        image_path: 摄像头的图片\n",
    "        identity: 字符串，想要验证的人的名字\n",
    "        database: 字典， 包含了成员姓名和对应编码\n",
    "        model: 训练好的模型\n",
    "    Returns:\n",
    "        dist: 摄像头中图片与数据库中图片的编码差距\n",
    "        is_open_door： True/False 是否开门\n",
    "    \"\"\"\n",
    "    # 计算图像的编码\n",
    "    # 计算图像的编码，使用fr_utils.img_to_encoding()来计算。\n",
    "    encoding = img_to_encoding(image_path, model)\n",
    "    # 计算与数据库中保存的编码的差距，这里使用tf的范数计算函数替换原文的np.linalg.norm\n",
    "    dist = tf.norm(encoding - database[identity])\n",
    "    # 判断是否打开门\n",
    "    if dist < 0.7:\n",
    "        print(\"欢迎 \" + str(identity) + \"回家！\")\n",
    "        is_door_open = True\n",
    "    else:\n",
    "        print(\"经验证，您与\" + str(identity) + \"不符！\")\n",
    "        is_door_open = False\n",
    "\n",
    "    return dist, is_door_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def who_is_it(image_path, database, model):\n",
    "    \"\"\"\n",
    "    根据指定的图片来进行人脸识别\n",
    "    Args:\n",
    "        image_path: 图片地址\n",
    "        database: 包含了名字与比那吗的字典\n",
    "        model: 训练好的图形\n",
    "    Returns:\n",
    "        min_dist: 字典中与输入图像最相近的编码\n",
    "        identity: 与min_dist对应的名字\n",
    "    \"\"\"\n",
    "    # 计算指定图像的编码，使用fr_utils.img_to_encoding()来计算。\n",
    "    encoding = img_to_encoding(image_path, model)\n",
    "    # 找到最相近的编码\n",
    "    min_dist = 100                  # 初始化min_dist变量为足够大的数字，这里设置为100\n",
    "    # 遍历数据库，找到min_dist\n",
    "    for name, db_enc in database.items():\n",
    "        dist = tf.norm(encoding - db_enc)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "    # 判断输入图像是否在数据库中\n",
    "    if min_dist > 0.7:\n",
    "        print(\"抱歉，您的信息不在数据库中。\")\n",
    "    else:\n",
    "        print(\"姓名\" + identity + \"  差距：\" + str(min_dist))\n",
    "\n",
    "    return min_dist, name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRmodel = u.faceRecoModel(input_shape=(3, 96, 96))\n",
    "# 编译模型\n",
    "FRmodel.compile(optimizer='adam', loss=triplet_loss, metrics=['accuracy'])\n",
    "# 加载权值\n",
    "u.load_weights_from_FaceNet(FRmodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据库\n",
    "database = creat_database(FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "who_is_it(\"./images/camera_0.jpg\", database, FRmodel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
