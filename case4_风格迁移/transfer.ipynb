{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interpreted-toyota",
   "metadata": {},
   "source": [
    "# 风格迁移\n",
    "### Ng的最后一个内容，用VGG实现的图片的风格迁移，依旧是加载好训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import st_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_content_cost(a_C, a_G):\n",
    "    \"\"\"\n",
    "    计算content损失\n",
    "    Args:\n",
    "        a_C: content图片的激活层输出（1，n_w，n_h，n_c）\n",
    "        a_G: generate图片的激活层输出（1，n_w，n_h，n_c）\n",
    "    Returns:\n",
    "        J_content: 计算得到的content损失\n",
    "    \"\"\"\n",
    "    # 获取维度信息\n",
    "    m, n_h, n_w, n_c = a_G.get_shape()\n",
    "    # 改变a_C，a_G的形状（降维，去掉第一个维度）\n",
    "    a_C_unrolled = tf.reshape(a_C, [n_h, n_w, n_c])\n",
    "    a_G_unrolled = tf.reshape(a_G, [n_h, n_w, n_c])\n",
    "    # 计算损失函数\n",
    "    J_content =  1./(4 * n_h * n_w * n_c) * tf.reduce_sum(tf.square(a_C_unrolled - a_G_unrolled))\n",
    "\n",
    "    return J_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-complex",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(A):\n",
    "    \"\"\"\n",
    "    创建gram矩阵\n",
    "    Args:\n",
    "        A: 矩阵（n_c，n_H*n_W）二维\n",
    "    Returns:\n",
    "        GA: A的gram矩阵（n_C,n_C）\n",
    "    \"\"\"\n",
    "    return tf.matmul(A, tf.transpose(A))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_layer_style_cost(a_S, a_G):\n",
    "    \"\"\"\n",
    "    计算每层的style损失\n",
    "    Arguments:\n",
    "        a_S: style图片的隐藏层激活输出 (1, n_H, n_W, n_C)\n",
    "        a_G: generate图片的隐藏层激活输出 (1, n_H, n_W, n_C)\n",
    "    Returns:\n",
    "        J_style_layer: 每层计算得到的style损失\n",
    "    \"\"\"\n",
    "    # 获取维度信息\n",
    "    m, n_h, n_w, n_c = a_G.get_shape()\n",
    "    # 改变a_C，a_G的形状（降维，将n_h和n_w展开至一个维度的形式）\n",
    "    a_S_unrolled = tf.reshape(a_S, [n_h*n_w, n_c])\n",
    "    a_G_unrolled = tf.reshape(a_G, [n_h*n_w, n_c])\n",
    "    # 生成style图和generate图的gram矩阵，将通道数作为第一个维度\n",
    "    GS = gram_matrix(tf.transpose(a_S_unrolled))\n",
    "    GG = gram_matrix(tf.transpose(a_G_unrolled))\n",
    "    assert GS.shape == (n_c, n_c)\n",
    "    # 计算该层的style损失\n",
    "    J_style_layer = 1 / (4 * (n_c ** 2) * ((n_h * n_w) ** 2)) * tf.reduce_sum(tf.square(GS - GG))\n",
    "\n",
    "    return J_style_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_style_cost(model, style_layers):\n",
    "    \"\"\"\n",
    "    从选择的层中计算所有的style损失\n",
    "    Args:\n",
    "        model: 训练好的模型\n",
    "        style_layers: 列表（层名，权重）\n",
    "    Returns:\n",
    "        J_style：计算得到的style损失\n",
    "    \"\"\"\n",
    "    # 初始化J_style\n",
    "    J_style = 0\n",
    "    for layer_name, coeff in style_layers:\n",
    "        out = model[layer_name]\n",
    "        a_S = sess.run(out)\n",
    "        a_G = out\n",
    "        J_style_layer = compute_layer_style_cost(a_S, a_G)\n",
    "        J_style += coeff * J_style_layer\n",
    "    return J_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_cost(J_content, J_style, alpha=10, beta=40):\n",
    "    \"\"\"\n",
    "    计算总的成本\n",
    "    Args:\n",
    "        J_content: content损失\n",
    "        J_style: style损失\n",
    "        alpha: content损失的权重，超参数\n",
    "        beta: style损失的权重，超参数\n",
    "    Returns:\n",
    "        J: 计算得到的总损失\n",
    "    \"\"\"\n",
    "    return alpha * J_content + beta * J_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_nn(sess, input_image, num_iteration=1000):\n",
    "\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    generated_image = sess.run(model['input'].assign(input_image))\n",
    "\n",
    "    for i in range(num_iteration):\n",
    "        sess.run(train_step)\n",
    "        generated_image = sess.run(model['input'])\n",
    "\n",
    "        # Print every 20 iteration.\n",
    "        if i % 20 == 0:\n",
    "            Jt, Jc, Js = sess.run([J, J_content, J_style])\n",
    "            print(\"Iteration \" + str(i) + \" :\")\n",
    "            print(\"total cost = \" + str(Jt))\n",
    "            print(\"content cost = \" + str(Jc))\n",
    "            print(\"style cost = \" + str(Js))\n",
    "\n",
    "            # save current generated image in the \"/output\" directory\n",
    "            st_utils.save_image(\"./output/\" + str(i) + \".png\", generated_image)\n",
    "\n",
    "        # save last generated image\n",
    "    st_utils.save_image('./output/generated_image.jpg', generated_image)\n",
    "\n",
    "    return generated_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "dir = './'\n",
    "sess = tf.compat.v1.InteractiveSession()\n",
    "STYLE_LAYERS = [('conv1_1', 0.2), ('conv2_1', 0.2), ('conv3_1', 0.2), ('conv4_1', 0.2), ('conv5_1', 0.2)]\n",
    "\n",
    "# 加载\"内容\"图像，整形并归一化\n",
    "content_image = Image.open( dir+'images/couple.jpg')\n",
    "content_image = content_image.resize((400,300))\n",
    "content_image = np.array(content_image)\n",
    "content_image = st_utils.reshape_and_normalize_image(content_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-automation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载\"风格\"图像，整形并归一化\n",
    "style_image = Image.open(dir + 'images/monet.jpg')\n",
    "style_image = style_image.resize((400,300))\n",
    "style_image = np.array(style_image)\n",
    "style_image = st_utils.reshape_and_normalize_image(style_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-highway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将\"内容\"图像添加噪音初始化为\"生成\"图像\n",
    "generated_image = st_utils.generate_noise_image(content_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-vegetable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "model = st_utils.load_vgg_model(dir + 'pretrained-model/imagenet-vgg-verydeep-19.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-front",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(model['input'].assign(content_image))\n",
    "out = model['conv4_2']\n",
    "a_C = sess.run(out)\n",
    "a_G = out\n",
    "J_content = compute_content_cost(a_C, a_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(model['input'].assign(style_image))\n",
    "J_style = compute_style_cost(model, STYLE_LAYERS)\n",
    "J = total_cost(J_content, J_style, 10, 40)\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(1.6)\n",
    "train_step = optimizer.minimize(J)\n",
    "model_nn(sess,generated_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
